
pig examples
============



// Get usage message

# ./pig -h

Usage: ./pig <options> ...
-h to print this usage info
-i to allocated interleaved memory
-k <MIN[:MAX]> set min and optional max percent spin load
-l <LOAD>, one of { 'spin', 'sleep', 'mem', 'int', 'fpu' }
   The spin load is the default, and the only load with variable percent
-m <N> to allocate <N> MBs of memory
-g for global per-process memory (rather than per thread memory)
-p <N> to fork <N> processes
-t <N> to create <N> threads
-s <N> to run for <N> seconds before quitting
-r to round robin bind processes to nodes
-v for verbose
-V to show version info



// Start one process spinning... until ^C

# ./pig
^CThreads:   1  Avg:  11.0  Stddev:   0.0  Min: 11  Max: 11



// Start one process spinning for 10 seconds

# ./pig -s10
Threads:   1  Avg:  33.0  Stddev:   0.0  Min: 33  Max: 33



// Run 10 processes spinning between 20-80% CPU utilization for 10 seconds

# ./pig -p10 -k20:80 -s10
Threads:   1  Avg:  13.0  Stddev:   0.0  Min: 13  Max: 13
Threads:   1  Avg:  13.0  Stddev:   0.0  Min: 13  Max: 13
Threads:   1  Avg:  12.0  Stddev:   0.0  Min: 12  Max: 12
Threads:   1  Avg:  13.0  Stddev:   0.0  Min: 13  Max: 13
Threads:   1  Avg:  13.0  Stddev:   0.0  Min: 13  Max: 13
Threads:   1  Avg:  14.0  Stddev:   0.0  Min: 14  Max: 14
Threads:   1  Avg:  14.0  Stddev:   0.0  Min: 14  Max: 14
Threads:   1  Avg:  12.0  Stddev:   0.0  Min: 12  Max: 12
Threads:   1  Avg:  15.0  Stddev:   0.0  Min: 15  Max: 15
Threads:   1  Avg:  15.0  Stddev:   0.0  Min: 15  Max: 15



// Run 10 processes for 10 seconds doing constant FPU work (e.g. sin(), sqrt())

# ./pig -p10 -s10 -l fpu
Threads:   1  Avg:  91.0  Stddev:   0.0  Min: 91  Max: 91
Threads:   1  Avg:  93.0  Stddev:   0.0  Min: 93  Max: 93
Threads:   1  Avg:  93.0  Stddev:   0.0  Min: 93  Max: 93
Threads:   1  Avg:  91.0  Stddev:   0.0  Min: 91  Max: 91
Threads:   1  Avg:  93.0  Stddev:   0.0  Min: 93  Max: 93
Threads:   1  Avg:  94.0  Stddev:   0.0  Min: 94  Max: 94
Threads:   1  Avg:  93.0  Stddev:   0.0  Min: 93  Max: 93
Threads:   1  Avg:  94.0  Stddev:   0.0  Min: 94  Max: 94
Threads:   1  Avg:  94.0  Stddev:   0.0  Min: 94  Max: 94
Threads:   1  Avg:  94.0  Stddev:   0.0  Min: 94  Max: 94



// Start 3 processes, each with 4 threads, spinning for 10 seconds

# ./pig -p3 -t4 -s10
Threads:   4  Avg:  32.0  Stddev:   0.0  Min: 32  Max: 32
Threads:   4  Avg:  31.8  Stddev:   0.4  Min: 31  Max: 32
Threads:   4  Avg:  32.0  Stddev:   0.0  Min: 32  Max: 32



// Verbosely run one process with 10 threads for 10 seconds.
// The table shows approximately how many seconds the thread ran on each CPU.
// Rows should normally sum to run-time seconds.

# ./pig -v -t10 -s10
system nodes = 8
system cpus  = 64
megabytes = 0
processes = 1
threads   = 10
seconds   = 10
min_pct   = 100
max_pct   = 100
Tally of times running on each cpu:
  @    0   1   3   8  11  16  18  19  20  27  32  35  37  40  43  48  51  53  56  59
     --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- ---
  0:   .   .   .   2   .   .   .   .   .   .   1   1   .   5   .   .   .   .   1   .
  1:   .   .   .   .   .   1   .   .   .   .   .   .   .   .   9   .   .   .   .   .
  2:   .   .   .   .   .   .   .   .   9   .   .   .   .   .   .   .   1   .   .   .
  3:   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  10
  4:   .   .  10   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .
  5:   .   .   .   .  10   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .
  6:   3   1   .   1   .   1   1   1   .   .   .   .   .   .   .   1   .   .   1   .
  7:   .   .   .   .   .   .   .   .   .  10   .   .   .   .   .   .   .   .   .   .
  8:   .   .   .   .   .   .   .   .   .   .   .   .  10   .   .   .   .   .   .   .
  9:   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  10   .   .
Work done on each thread:
  0:       31
  1:       31
  2:       33
  3:       33
  4:       32
  5:       32
  6:       31
  7:       33
  8:       31
  9:       33
Threads:  10  Avg:  32.0  Stddev:   0.9  Min: 31  Max: 33



// Verbosely run one process with 10 threads for 100 seconds.
// A couple of the threads ran on several different CPUs...

# ./pig -v -t10 -s100
system nodes = 8
system cpus  = 64
megabytes = 0
processes = 1
threads   = 10
seconds   = 100
min_pct   = 100
max_pct   = 100
Tally of times running on each cpu:
  @    0   3   8  11  16  19  24  27  28  32  35  40  41  43  45  48  51  53  56  59
     --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- ---
  0:  32   .  24   .   2   .   5   .   .  10   .   8   1   1   .   2   .   .  15   .
  1:  29   .  24   .   6   .   7   .   .  10   .   5   .   .   .   6   1   .  12   .
  2:   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . 100
  3:   . 100   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .
  4:   .   .   . 100   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .
  5:   .   .   .   .   . 100   .   .   .   .   .   .   .   .   .   .   .   .   .   .
  6:   1   .   1   .   .   .   .  45  53   .   .   .   .   .   .   .   .   .   .   .
  7:   .   .   .   .   .   .   .   .   .   . 100   .   .   .   .   .   .   .   .   .
  8:   .   .   .   .   .   .   .   .   .   .   .   .   .   . 100   .   .   .   .   .
  9:   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . 100   .   .
Work done on each thread:
  0:      316
  1:      318
  2:      332
  3:      324
  4:      323
  5:      334
  6:      333
  7:      321
  8:      321
  9:      331
Threads:  10  Avg: 325.3  Stddev:   6.3  Min: 316  Max: 334



// Run 8 processes for 100 seconds that mostly sleep,
// but also consume 8GB RAM each

# ./pig -p8 -s100 -l sleep -m 8000 &
[1] 45965
# 
# jobs
[1]+  Running                 ./pig -p8 -s100 -l sleep -m 8000 &
# 
# uptime
 11:33:32 up 18 days, 17:47,  1 user,  load average: 0.03, 0.08, 0.25
# 
# /shak/bgray/nmstat_tool/nmstat -n pig
Per-node process memory usage (in MBs):
            PID             N0             N1             N2             N3             N4             N5             N6             N7
     ----------     ----------     ----------     ----------     ----------     ----------     ----------     ----------     ----------
          45965           0.00        8000.13           0.05           0.00           0.00           0.02           0.45           0.02
          45966           0.00           0.11        8000.05           0.00           0.00           0.00           0.14           0.01
          45967           0.00           0.11           0.03        8000.02           0.00           0.00           0.14           0.01
          45968           0.00           0.11           0.03           0.00        8000.02           0.00           0.14           0.01
          45969           0.00           0.11           0.03           0.00           0.00        8000.03           0.14           0.01
          45970           0.00           0.11           0.03           0.00           0.00           0.00        8000.16           0.01
          45971           0.00           0.11           0.03           0.00           0.00           0.00           0.14        8000.04
          45972        8000.01           0.12           0.03           0.00           0.00           0.00           0.14           0.01
Threads:   1  Avg:  98.0  Stddev:   0.0  Min: 98  Max: 98
Threads:   1  Avg:  98.0  Stddev:   0.0  Min: 98  Max: 98
Threads:   1  Avg:  98.0  Stddev:   0.0  Min: 98  Max: 98
Threads:   1  Avg:  98.0  Stddev:   0.0  Min: 98  Max: 98
Threads:   1  Avg:  98.0  Stddev:   0.0  Min: 98  Max: 98
Threads:   1  Avg:  98.0  Stddev:   0.0  Min: 98  Max: 98
Threads:   1  Avg:  98.0  Stddev:   0.0  Min: 98  Max: 98
Threads:   1  Avg:  98.0  Stddev:   0.0  Min: 98  Max: 98



// Verbosely run 1 process with 8 threads for 100 seconds using global
// process-wide 8GB memory and between 30% to 80% CPU utilization.
// This is kind of like a fake VM guest, except the load is just spinning
// and not generating much memory traffic at all.

[root@perf37 pig_tool]# ./pig -v -p1 -t8 -s100 -gm8000 -k30:80
system nodes = 8
system cpus  = 64
megabytes = 8000
processes = 1
threads   = 8
seconds   = 100
min_pct   = 30
max_pct   = 80
Tally of times running on each cpu:
  @    0   2   3   6  11  19  27  28  35  42  48  59
     --- --- --- --- --- --- --- --- --- --- --- ---
  0:   .   .   .   .   .   .   .   .   .   .   . 100
  1:   .  56  44   .   .   .   .   .   .   .   .   .
  2:   .   .   .   . 100   .   .   .   .   .   .   .
  3:   .   .   .   .   . 100   .   .   .   .   .   .
  4:   .   .   .   .   .   .   2  98   .   .   .   .
  5:   .   .   .   .   .   .   .   . 100   .   .   .
  6:   .   1   1   1   .   .   .   .   .   .  97   .
  7:   1   .   1   .   .   .   .   .   .  98   .   .
Work done on each thread:
  0:      161
  1:      171
  2:      164
  3:      158
  4:      164
  5:      172
  6:      161
  7:      163
Threads:   8  Avg: 164.2  Stddev:   4.6  Min: 158  Max: 172



// Verbosely run three 8 VCPU 8GB "guests" for 100 seconds with variable CPU load.
// Note that the scheduler runs the threads all over the system...  

# ./pig -v -p3 -t8 -s100 -gm8000 -k30:80
system nodes = 8
system cpus  = 64
megabytes = 8000
processes = 3
threads   = 8
seconds   = 100
min_pct   = 30
max_pct   = 80
Tally of times running on each cpu:
  46243  @    0   1   2   3   4   8   9  10  12  16  17  18  19  20  21  22  24  25  26  27  30  32  34  35  36  38  40  41  42  43  44  45  46  47  48  49  51  52  54  56  59  62
  46243     --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- ---
  46243  0:   .   .   .   .   .   .   .   7  48   .   .   .   .   .   .   .   .   .   .   .   .   .   5  19  14   6   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   1
  46243  1:   3   .   .   .   .   3   .   .   .   .   .   .   .   .   .   .   .   7   .   .   .   .   .   .   .   .   .   .   1   1  17   9  25   .   1   .   .   .  33   .   .   .
  46243  2:   .   .   .   .   .   .   .   .   .   4   .   5   .  17   .   .   8   .   6   .  44   3   .   .   .   2   .   .   .   1   .   .   2   2   3   .   3   .   .   .   .   .
  46243  3:   .   .   .   .   .  10   1   2   .   8  16  22  11   5   .   1   .   .   .   .   .   .   .   .   .   .   5   .   .   .   .   .   .   .   .   .   .   .   .   .  19   .
  46243  4:   .   .   .   3   .   .   .   .  33   .   .   .   .   .   .   .   8  18  11  27   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .
  46243  5:  10   .   9   .  23   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   3   1   .  17   4  33   .   .   .   .   .   .   .   .   .   .
  46243  6:   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   1  26   .   8  65   .   .   .   .   .   .   .   .
  46243  7:   6   1   .   .   .   .   .   .   .   1   .   .   .   .  43   .   .   .   .   .   .   .   .   .   .   .   3   2   .   .   .   .   .   .  10  12   1  18   .   3   .   .
Work done on each thread:
  0:      151
  1:      147
  2:      143
  3:      145
  4:      148
  5:      152
  6:      145
  7:      140
Threads:   8  Avg: 146.4  Stddev:   3.7  Min: 140  Max: 152
Tally of times running on each cpu:
  46242  @    0   1   2   3   4   6   8   9  16  17  18  19  20  22  24  25  26  27  29  32  34  35  36  38  40  41  42  43  46  48  49  50  51  52  53  54  56  58  59  60  62
  46242     --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- ---
  46242  0:   .   .   .   .   .   .   .   .   2   .   .   .   .   .   2   .   4  25  49   6   .   .   .   .   2   .   7   1   .   .   2   .   .   .   .   .   .   .   .   .   .
  46242  1:   2   7   .   .   .   .   .   5   3   7   .   .   .   1   5   .   3   .   .   7   3   1  26  11   5   1   1   1   2   .   .   .   .   .   .   .   9   .   .   .   .
  46242  2:   7   2  48   .   .   3   .   .   .   .   .   .   .   .   5   .   .   .   .   .   4   .   .   .   1   .   2   1   .   .   .   .   .   2   .   .   2   5   .   .  18
  46242  3:   9   .   2   .   .   .   1   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   2   4   .   .   .   1   7   .  66   1   .   .   .   7   .   .   .   .
  46242  4:   .   .   .   .   .   .  12   .   .   .   .   .   .   .   2   .   .   .   .   .   .   .   .   .   1   1   .  15   .   1   .   .   .   .   .   .  13   3   1  51   .
  46242  5:   .   .   1   2   .   .   .   .   3   .  16   6   .   .   2   .   .   .   .   1   2   2   .  35   1   3   6  16   .   2   .   .   .   2   .   .   .   .   .   .   .
  46242  6:   1   .   .   .   8   .   6  17   2   .   .   .   2   .   .   2   .   .   .   .   .   2   .   .   1   .   .   .   .   .   .   6   .  12   1  40   .   .   .   .   .
  46242  7:   .   .   .   .   .   .   .   .   2   .   .   .   .   .   .   .   .   .   .   9  17  12   5  10   .   .   .   .   .  16   .   .   .  18   .   .   2   9   .   .   .
Work done on each thread:
  0:      149
  1:      151
  2:      155
  3:      152
  4:      151
  5:      152
  6:      143
  7:      155
Threads:   8  Avg: 151.0  Stddev:   3.6  Min: 143  Max: 155
[root@perf37 pig_tool]# Tally of times running on each cpu:
  46244  @    0   1   2   3   4   6   8   9  11  12  14  16  17  18  20  22  23  24  25  26  28  29  30  31  32  33  36  40  41  43  48  49  50  51  54  56  57  58  59  60  61  62
  46244     --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- ---
  46244  0:   .   .   .   .   .   .   .   .   .   .   .   1   .  29   .   6   9   .   .   .   .   .   2  39   .   .   .  12   .   2   .   .   .   .   .   .   .   .   .   .   .   .
  46244  1:   .   7   .   .   .   .   .   .   .   .   .   7   7   .  21  40   1   .   .   .   .   .   .   .   .   .   .   .   .   .  15   .   .   2   .   .   .   .   .   .   .   .
  46244  2:   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   5   .   .   .   .   .   .   .   .   .   .   .   .   2  39   .  54
  46244  3:   8   .   2   2   .  65   .   .   .   .   .   2   1   .   .   .   .   .   6   .   .   .   .   .   .   .   .   5   2   .   .   .   .   .   .   6   .   1   .   .   .   .
  46244  4:   6   .   .   .   .   .   2   .  53   .   .   .   .   .   .   .   .   1   .   .   .   .   9   .   .  29   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .
  46244  5:   .   .   .   .   .   .   2   .   .   .   .   .   .   .   .   .   .   3   1   6   1  32   .   .   7   6  12   1   .   .   .   .   1   1   7   .   .   .   .   .   .  20
  46244  6:   .   .   .   .   .   .   2   .   .   8  80   1   8   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   1   .   .   .   .   .   .   .   .
  46244  7:   1   .   .   .  43   .   4   2   .   .   .   8   1   .   .   .   8   .   .   .   .   .   .   .   2   .   .   .   .   .   .   1   .   .   .  23   1   2   1   2   1   .
Work done on each thread:
  0:      146
  1:      144
  2:      148
  3:      151
  4:      152
  5:      153
  6:      150
  7:      143
Threads:   8  Avg: 148.4  Stddev:   3.5  Min: 143  Max: 153



// Verbosely run three 8 VCPU 8GB "guests" with variable CPU load for 100 seconds.
// The "-r" option here round-robin pins the processes to different nodes.
// The scheduler still spreads them across the node CPUs -- probably because of the "variable" load.

# ./pig -v -p3 -t8 -s100 -rgm8000 -k30:80
system nodes = 8
system cpus  = 64
megabytes = 8000
processes = 3
threads   = 8
seconds   = 100
min_pct   = 30
max_pct   = 80
Tally of times running on each cpu:
  46190  @   16  17  18  19  20  21  22  23
  46190     --- --- --- --- --- --- --- ---
  46190  0:  20  16  14  10   6   6  14  14
  46190  1:   6   9  11  22  17  12   7  16
  46190  2:  20  11  11  19   9  14   4  12
  46190  3:   8   6  15  19  15  15   7  15
  46190  4:  10  15  11   8  12  14  13  17
  46190  5:  11  13  11  16   7  19   8  15
  46190  6:  17  16   7   7  15  16  11  11
  46190  7:  14  18  13   6  10  17  11  11
Work done on each thread:
  0:      137
  1:      135
  2:      132
  3:      138
  4:      133
  5:      132
  6:      135
  7:      138
Threads:   8  Avg: 135.0  Stddev:   2.3  Min: 132  Max: 138
Tally of times running on each cpu:
  46188  @    0   1   2   3   4   5   6   7
  46188     --- --- --- --- --- --- --- ---
  46188  0:   7  20  26  14   6   2  11  14
  46188  1:  14  18  13  18   9   9   6  13
  46188  2:  12  12  13  10   7  25  11  10
  46188  3:   8  19   9   9   9  14  10  22
  46188  4:  11   8  12  14  12  15  13  15
  46188  5:  10  15   9  12  12  13  11  18
  46188  6:  11  11  13  19   7  16  16   7
  46188  7:  13  10  14  13   9  18  12  11
Work done on each thread:
  0:      136
  1:      130
  2:      127
  3:      135
  4:      135
  5:      138
  6:      133
  7:      129
Threads:   8  Avg: 132.9  Stddev:   3.6  Min: 127  Max: 138
[root@perf37 pig_tool]# Tally of times running on each cpu:
  46189  @    8   9  10  11  12  13  14  15
  46189     --- --- --- --- --- --- --- ---
  46189  0:  15  23  14  10   4   8  17   9
  46189  1:  11  14   8  12  11  23   9  12
  46189  2:  11  10  16  14  10  17   8  14
  46189  3:   6   8   8  20  13  17  10  18
  46189  4:  13  17   7  17  13  11   9  13
  46189  5:  10  17  17  10  13   9  13  11
  46189  6:   7  10   9  18  12  13  13  18
  46189  7:   8  15  11  16  13  11  14  12
Work done on each thread:
  0:      140
  1:      135
  2:      135
  3:      140
  4:      139
  5:      135
  6:      130
  7:      135
Threads:   8  Avg: 136.1  Stddev:   3.2  Min: 130  Max: 140



// Verbosely run three 8 VCPU 8GB "guests" with 100% CPU load for 100 seconds.
// The scheduler does much better here with constant load -- even without any pinning.

[root@perf37 pig_tool]# ./pig -v -p3 -t8 -s100 -gm8000 
system nodes = 8
system cpus  = 64
megabytes = 8000
processes = 3
threads   = 8
seconds   = 100
min_pct   = 100
max_pct   = 100
Tally of times running on each cpu:
  46462  @    3  11  19  27  32  35  43  45  53  57
  46462     --- --- --- --- --- --- --- --- --- ---
  46462  0:   .   .   .   .   .   . 100   .   .   .
  46462  1: 100   .   .   .   .   .   .   .   .   .
  46462  2:   . 100   .   .   .   .   .   .   .   .
  46462  3:   .   . 100   .   .   .   .   .   .   .
  46462  4:   .   .   . 100   .   .   .   .   .   .
  46462  5:   .   .   .   .   . 100   .   .   .   .
  46462  6:   .   .   .   .   .   .   .   1   .  99
  46462  7:   .   .   .   .  99   .   .   .   1   .
Work done on each thread:
  0:      270
  1:      272
  2:      273
  3:      273
  4:      273
  5:      273
  6:      273
  7:      273
Threads:   8  Avg: 272.5  Stddev:   1.0  Min: 270  Max: 273
[root@perf37 pig_tool]# Tally of times running on each cpu:
  46464  @    5  13  21  29  45  52  53  59  61  62
  46464     --- --- --- --- --- --- --- --- --- ---
  46464  0:   .   .   .   .   .   .   . 100   .   .
  46464  1: 100   .   .   .   .   .   .   .   .   .
  46464  2:   . 100   .   .   .   .   .   .   .   .
  46464  3:   .   . 100   .   .   .   .   .   .   .
  46464  4:   .   .   . 100   .   .   .   .   .   .
  46464  5:   .   .   .   . 100   .   .   .   .   .
  46464  6:   .   .   .   .   .  90  10   .   .   .
  46464  7:   .   .   .   .   .   .   .   .  17  83
Work done on each thread:
  0:      273
  1:      273
  2:      273
  3:      273
  4:      273
  5:      273
  6:      272
  7:      272
Threads:   8  Avg: 272.8  Stddev:   0.4  Min: 272  Max: 273
Tally of times running on each cpu:
  46463  @    7  15  23  31  37  47  51  55
  46463     --- --- --- --- --- --- --- ---
  46463  0:   .   .   .   .   .   . 100   .
  46463  1:   .   .   .   .   .   .   . 100
  46463  2: 100   .   .   .   .   .   .   .
  46463  3:   . 100   .   .   .   .   .   .
  46463  4:   .   . 100   .   .   .   .   .
  46463  5:   .   .   . 100   .   .   .   .
  46463  6:   .   .   .   . 100   .   .   .
  46463  7:   .   .   .   .   . 100   .   .
Work done on each thread:
  0:      272
  1:      273
  2:      273
  3:      273
  4:      273
  5:      273
  6:      273
  7:      273
Threads:   8  Avg: 272.9  Stddev:   0.3  Min: 272  Max: 273


// Verbosely run three 8 VCPU 8GB "guests" with 100% CPU load for 100 seconds.
// Perfect scheduling here with "-r" pinning option.  Effective work done per thread
// goes down a bit, but remember there is little memory traffic in this spin load.

# ./pig -v -p3 -t8 -s100 -rgm8000 
system nodes = 8
system cpus  = 64
megabytes = 8000
processes = 3
threads   = 8
seconds   = 100
min_pct   = 100
max_pct   = 100
Tally of times running on each cpu:
  46675  @   16  17  18  19  20  21  22  23
  46675     --- --- --- --- --- --- --- ---
  46675  0: 100   .   .   .   .   .   .   .
  46675  1:   .   .   . 100   .   .   .   .
  46675  2:   .   .   .   .   . 100   .   .
  46675  3:   .   .   .   .   .   .   . 100
  46675  4:   . 100   .   .   .   .   .   .
  46675  5:   .   . 100   .   .   .   .   .
  46675  6:   .   .   .   . 100   .   .   .
  46675  7:   .   .   .   .   .   . 100   .
Work done on each thread:
  0:      252
  1:      252
  2:      252
  3:      252
  4:      252
  5:      251
  6:      251
  7:      252
Threads:   8  Avg: 251.8  Stddev:   0.4  Min: 251  Max: 252
Tally of times running on each cpu:
  46674  @    8   9  10  11  12  13  14  15
  46674     --- --- --- --- --- --- --- ---
  46674  0:   . 100   .   .   .   .   .   .
  46674  1:   .   .   . 100   .   .   .   .
  46674  2:   .   .   .   .   . 100   .   .
  46674  3:   .   .   .   .   .   .   . 100
  46674  4: 100   .   .   .   .   .   .   .
  46674  5:   .   .   .   . 100   .   .   .
  46674  6:   .   . 100   .   .   .   .   .
  46674  7:   .   .   .   .   .   . 100   .
Work done on each thread:
  0:      252
  1:      252
  2:      252
  3:      252
  4:      251
  5:      252
  6:      251
  7:      252
Threads:   8  Avg: 251.8  Stddev:   0.4  Min: 251  Max: 252
Tally of times running on each cpu:
  46673  @    0   1   2   3   4   5   6   7
  46673     --- --- --- --- --- --- --- ---
  46673  0: 100   .   .   .   .   .   .   .
  46673  1:   .   .   . 100   .   .   .   .
  46673  2:   .   .   .   .   . 100   .   .
  46673  3:   .   .   .   .   .   .   . 100
  46673  4:   . 100   .   .   .   .   .   .
  46673  5:   .   . 100   .   .   .   .   .
  46673  6:   .   .   .   . 100   .   .   .
  46673  7:   .   .   .   .   .   . 100   .
Work done on each thread:
  0:      250
  1:      252
  2:      252
  3:      252
  4:      251
  5:      252
  6:      252
  7:      252
Threads:   8  Avg: 251.6  Stddev:   0.7  Min: 250  Max: 252



// Verbosely run 3 "guest" processes with 8 VCPU threads
// and 8GB RAM for 60 seconds with a heavy memory load.
// Note the slow remote memory makes times tally total to be less than 60

# ./pig -v -p3 -t8 -gm8000 -s60 -l mem
system nodes = 8
system cpus  = 64
megabytes = 8000
processes = 3
threads   = 8
seconds   = 60
min_pct   = 100
max_pct   = 100
Tally of times running on each cpu:
  38793  @    3  27  29  35  37  41  43  51  59
  38793     --- --- --- --- --- --- --- --- ---
  38793  0:   .   1   .   .   .  42   .   .   .
  38793  1:   .   .   .  34   .   .   .   .   .
  38793  2:   .   .   .   .   .   .  43   .   .
  38793  3:   .   .   .   .   .   .   .  37   .
  38793  4:   .   .   .   .   .   .   .   .  46
  38793  5:  37   .   .   .   .   .   .   .   .
  38793  6:   .   .  44   .   .   .   .   .   .
  38793  7:   .   .   .   .  34   .   .   .   .
Work done on each thread:
  0:       42
  1:       33
  2:       42
  3:       36
  4:       45
  5:       36
  6:       46
  7:       33
Threads:   8  Avg:  39.1  Stddev:   4.9  Min: 33  Max: 46
Tally of times running on each cpu:
  38791  @    5  10  13  15  21  27  53  61
  38791     --- --- --- --- --- --- --- ---
  38791  0:   .  59   .   .   .   .   .   .
  38791  1:   .   .  59   .   .   .   .   .
  38791  2:   .   .   .   .  37   .   .   .
  38791  3:   .   .   .   .   .  44   .   .
  38791  4:   .   .   .   .   .   .  38   .
  38791  5:   .   .   .   .   .   .   .  45
  38791  6:  52   .   .   .   .   .   .   .
  38791  7:   .   .   .  59   .   .   .   .
Work done on each thread:
  0:       66
  1:       66
  2:       36
  3:       43
  4:       37
  5:       44
  6:       51
  7:       66
Threads:   8  Avg:  51.1  Stddev:  12.3  Min: 36  Max: 66
Tally of times running on each cpu:
  38792  @    7  19  23  31  39  45  55  63
  38792     --- --- --- --- --- --- --- ---
  38792  0:   .  56   .   .   .   .   .   .
  38792  1:   .   .  56   .   .   .   .   .
  38792  2:   .   .   .  45   .   .   .   .
  38792  3:   .   .   .   .  45   .   .   .
  38792  4:   .   .   .   .   .  39   .   .
  38792  5:   .   .   .   .   .   .  44   .
  38792  6:   .   .   .   .   .   .   .  38
  38792  7:  45   .   .   .   .   .   .   .
Work done on each thread:
  0:       62
  1:       62
  2:       44
  3:       44
  4:       38
  5:       43
  6:       37
  7:       44
Threads:   8  Avg:  46.8  Stddev:   9.2  Min: 37  Max: 62



// Verbosely run 3 "guest" pinned processes with 8 VCPU threads
// and 8GB RAM for 60 seconds with a memory load.
// Note the effective work done doubles versus the unpinned "guests" above.

# ./pig -v -p3 -t8 -rgm8000 -s60 -l mem
system nodes = 8
system cpus  = 64
megabytes = 8000
processes = 3
threads   = 8
seconds   = 60
min_pct   = 100
max_pct   = 100
Tally of times running on each cpu:
  38838  @    8   9  10  11  12  13  14  15
  38838     --- --- --- --- --- --- --- ---
  38838  0:   .  60   .   .   .   .   .   .
  38838  1:   .   .   .  60   .   .   .   .
  38838  2:   .   .   .   .   .  60   .   .
  38838  3:   .   .   .   .   .   .   .  60
  38838  4:  60   .   .   .   .   .   .   .
  38838  5:   .   .  60   .   .   .   .   .
  38838  6:   .   .   .   .   .   .  60   .
  38838  7:   .   .   .   .  60   .   .   .
Work done on each thread:
  0:       91
  1:       91
  2:       91
  3:       91
  4:       91
  5:       91
  6:       91
  7:       91
Threads:   8  Avg:  91.0  Stddev:   0.0  Min: 91  Max: 91
Tally of times running on each cpu:
  38839  @   16  17  18  19  20  21  22  23
  38839     --- --- --- --- --- --- --- ---
  38839  0:  60   .   .   .   .   .   .   .
  38839  1:   .   .   .  60   .   .   .   .
  38839  2:   .   .   .   .   .  60   .   .
  38839  3:   .   .   .   .   .   .   .  60
  38839  4:   .  60   .   .   .   .   .   .
  38839  5:   .   .  60   .   .   .   .   .
  38839  6:   .   .   .   .  60   .   .   .
  38839  7:   .   .   .   .   .   .  60   .
Work done on each thread:
  0:       90
  1:       90
  2:       90
  3:       90
  4:       90
  5:       90
  6:       90
  7:       90
Threads:   8  Avg:  90.0  Stddev:   0.0  Min: 90  Max: 90
Tally of times running on each cpu:
  38837  @    0   1   2   3   4   5   6   7
  38837     --- --- --- --- --- --- --- ---
  38837  0:   .  60   .   .   .   .   .   .
  38837  1:   .   .   .  60   .   .   .   .
  38837  2:   .   .   .   .   .  60   .   .
  38837  3:   .   .   .   .   .   .   .  60
  38837  4:  60   .   .   .   .   .   .   .
  38837  5:   .   .   .   .  60   .   .   .
  38837  6:   .   .  60   .   .   .   .   .
  38837  7:   .   .   .   .   .   .  60   .
Work done on each thread:
  0:       90
  1:       90
  2:       90
  3:       90
  4:       90
  5:       90
  6:       90
  7:       90
Threads:   8  Avg:  90.0  Stddev:   0.0  Min: 90  Max: 90


